{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b44833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset('roneneldan/TinyStories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e18409b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2119719, 21990)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "from tokenizers.normalizers import Lowercase, NFD, StripAccents, Sequence\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 抽取所有文本（这里假设字段名是 'text'，你可以根据实际调整）\n",
    "def get_all_texts(split):\n",
    "    # return [item['text'] for item in dataset[split]]\n",
    "    return dataset[split][\"text\"]\n",
    "\n",
    "train_texts = get_all_texts('train')\n",
    "validation_texts = get_all_texts('validation')\n",
    "\n",
    "len(train_texts), len(validation_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a49f6a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokenizer with vocab size: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training tokenizer: 100%|██████████| 2119719/2119719 [00:48<00:00, 44119.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokens for 'Once upon a time, there was a cat.': ['once', 'upon', 'a', 'time', ',', 'there', 'was', 'a', 'cat', '.']\n",
      "Tokens for 'The cat loved to chase butterflies.': ['the', 'cat', 'loved', 'to', 'ch', 'ase', 'butter', 'f', 'li', 'es', '.']\n",
      "Tokens for 'One day, it caught a butterfly and became friends with it.': ['one', 'day', ',', 'it', 'ca', 'ught', 'a', 'butter', 'fly', 'and', 'became', 'friends', 'with', 'it', '.']\n",
      "Tokens for 'huggingface transformers is a great library for NLP tasks.': ['hug', 'g', 'ing', 'face', 't', 'ran', 's', 'for', 'm', 'ers', 'is', 'a', 'great', 'li', 'br', 'ar', 'y', 'for', 'n', 'l', 'p', 't', 'ask', 's', '.']\n",
      "Tokens for 'The ephemeral zephyr whispered through the desolate moor at twilight.': ['the', 'ep', 'he', 'm', 'er', 'al', 'z', 'ep', 'h', 'y', 'r', 'w', 'his', 'per', 'ed', 'through', 'the', 'de', 'so', 'l', 'ate', 'mo', 'or', 'at', 't', 'w', 'il', 'ight', '.']\n",
      "Training tokenizer with vocab size: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training tokenizer: 100%|██████████| 2119719/2119719 [00:47<00:00, 44643.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokens for 'Once upon a time, there was a cat.': ['once', 'upon', 'a', 'time', ',', 'there', 'was', 'a', 'cat', '.']\n",
      "Tokens for 'The cat loved to chase butterflies.': ['the', 'cat', 'loved', 'to', 'ch', 'ase', 'butter', 'fli', 'es', '.']\n",
      "Tokens for 'One day, it caught a butterfly and became friends with it.': ['one', 'day', ',', 'it', 'caught', 'a', 'butterfly', 'and', 'became', 'friends', 'with', 'it', '.']\n",
      "Tokens for 'huggingface transformers is a great library for NLP tasks.': ['hug', 'g', 'ing', 'face', 't', 'ran', 's', 'for', 'm', 'ers', 'is', 'a', 'great', 'li', 'br', 'ary', 'for', 'n', 'l', 'p', 't', 'asks', '.']\n",
      "Tokens for 'The ephemeral zephyr whispered through the desolate moor at twilight.': ['the', 'ep', 'he', 'm', 'er', 'al', 'z', 'ep', 'h', 'y', 'r', 'whis', 'per', 'ed', 'through', 'the', 'de', 'so', 'late', 'mo', 'or', 'at', 'tw', 'il', 'ight', '.']\n",
      "Training tokenizer with vocab size: 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training tokenizer: 100%|██████████| 2119719/2119719 [00:50<00:00, 42195.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokens for 'Once upon a time, there was a cat.': ['once', 'upon', 'a', 'time', ',', 'there', 'was', 'a', 'cat', '.']\n",
      "Tokens for 'The cat loved to chase butterflies.': ['the', 'cat', 'loved', 'to', 'chase', 'butterflies', '.']\n",
      "Tokens for 'One day, it caught a butterfly and became friends with it.': ['one', 'day', ',', 'it', 'caught', 'a', 'butterfly', 'and', 'became', 'friends', 'with', 'it', '.']\n",
      "Tokens for 'huggingface transformers is a great library for NLP tasks.': ['hug', 'ging', 'face', 't', 'ran', 's', 'form', 'ers', 'is', 'a', 'great', 'library', 'for', 'n', 'l', 'p', 't', 'asks', '.']\n",
      "Tokens for 'The ephemeral zephyr whispered through the desolate moor at twilight.': ['the', 'ep', 'he', 'mer', 'al', 'z', 'ep', 'h', 'y', 'r', 'whispered', 'through', 'the', 'de', 'so', 'late', 'mo', 'or', 'at', 'tw', 'il', 'ight', '.']\n",
      "Training tokenizer with vocab size: 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training tokenizer: 100%|██████████| 2119719/2119719 [00:56<00:00, 37723.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokens for 'Once upon a time, there was a cat.': ['once', 'upon', 'a', 'time', ',', 'there', 'was', 'a', 'cat', '.']\n",
      "Tokens for 'The cat loved to chase butterflies.': ['the', 'cat', 'loved', 'to', 'chase', 'butterflies', '.']\n",
      "Tokens for 'One day, it caught a butterfly and became friends with it.': ['one', 'day', ',', 'it', 'caught', 'a', 'butterfly', 'and', 'became', 'friends', 'with', 'it', '.']\n",
      "Tokens for 'huggingface transformers is a great library for NLP tasks.': ['hugging', 'face', 'trans', 'form', 'ers', 'is', 'a', 'great', 'library', 'for', 'n', 'l', 'p', 'tasks', '.']\n",
      "Tokens for 'The ephemeral zephyr whispered through the desolate moor at twilight.': ['the', 'ep', 'he', 'mer', 'al', 'z', 'ep', 'h', 'y', 'r', 'whispered', 'through', 'the', 'de', 'so', 'late', 'mo', 'or', 'at', 'tw', 'il', 'ight', '.']\n",
      "Training tokenizer with vocab size: 16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training tokenizer: 100%|██████████| 2119719/2119719 [00:44<00:00, 47379.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokens for 'Once upon a time, there was a cat.': ['once', 'upon', 'a', 'time', ',', 'there', 'was', 'a', 'cat', '.']\n",
      "Tokens for 'The cat loved to chase butterflies.': ['the', 'cat', 'loved', 'to', 'chase', 'butterflies', '.']\n",
      "Tokens for 'One day, it caught a butterfly and became friends with it.': ['one', 'day', ',', 'it', 'caught', 'a', 'butterfly', 'and', 'became', 'friends', 'with', 'it', '.']\n",
      "Tokens for 'huggingface transformers is a great library for NLP tasks.': ['hugging', 'face', 'transform', 'ers', 'is', 'a', 'great', 'library', 'for', 'n', 'l', 'p', 'tasks', '.']\n",
      "Tokens for 'The ephemeral zephyr whispered through the desolate moor at twilight.': ['the', 'ep', 'he', 'mer', 'al', 'z', 'ep', 'hy', 'r', 'whispered', 'through', 'the', 'de', 'so', 'late', 'mo', 'or', 'at', 'twilight', '.']\n",
      "Training tokenizer with vocab size: 32000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training tokenizer: 100%|██████████| 2119719/2119719 [01:02<00:00, 33744.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokens for 'Once upon a time, there was a cat.': ['once', 'upon', 'a', 'time', ',', 'there', 'was', 'a', 'cat', '.']\n",
      "Tokens for 'The cat loved to chase butterflies.': ['the', 'cat', 'loved', 'to', 'chase', 'butterflies', '.']\n",
      "Tokens for 'One day, it caught a butterfly and became friends with it.': ['one', 'day', ',', 'it', 'caught', 'a', 'butterfly', 'and', 'became', 'friends', 'with', 'it', '.']\n",
      "Tokens for 'huggingface transformers is a great library for NLP tasks.': ['hugging', 'face', 'transform', 'ers', 'is', 'a', 'great', 'library', 'for', 'n', 'l', 'p', 'tasks', '.']\n",
      "Tokens for 'The ephemeral zephyr whispered through the desolate moor at twilight.': ['the', 'ep', 'he', 'mer', 'al', 'z', 'ep', 'hy', 'r', 'whispered', 'through', 'the', 'desolate', 'mo', 'or', 'at', 'twilight', '.']\n",
      "Training tokenizer with vocab size: 50257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training tokenizer: 100%|██████████| 2119719/2119719 [00:51<00:00, 41517.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokens for 'Once upon a time, there was a cat.': ['once', 'upon', 'a', 'time', ',', 'there', 'was', 'a', 'cat', '.']\n",
      "Tokens for 'The cat loved to chase butterflies.': ['the', 'cat', 'loved', 'to', 'chase', 'butterflies', '.']\n",
      "Tokens for 'One day, it caught a butterfly and became friends with it.': ['one', 'day', ',', 'it', 'caught', 'a', 'butterfly', 'and', 'became', 'friends', 'with', 'it', '.']\n",
      "Tokens for 'huggingface transformers is a great library for NLP tasks.': ['hugging', 'face', 'transform', 'ers', 'is', 'a', 'great', 'library', 'for', 'n', 'l', 'p', 'tasks', '.']\n",
      "Tokens for 'The ephemeral zephyr whispered through the desolate moor at twilight.': ['the', 'ep', 'he', 'mer', 'al', 'zephyr', 'whispered', 'through', 'the', 'desolate', 'moor', 'at', 'twilight', '.']\n"
     ]
    }
   ],
   "source": [
    "def iter_with_progress():\n",
    "    for text in tqdm(train_texts, desc=\"Training tokenizer\"):\n",
    "        yield text\n",
    "\n",
    "\n",
    "# 50257 is the default vocab size for GPT-2\n",
    "vocab_sizes = [1000, 2000, 4000, 8000, 16000, 32000, 50257]\n",
    "\n",
    "for vocab_size in vocab_sizes:\n",
    "    print(f\"Training tokenizer with vocab size: {vocab_size}\")\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size=vocab_size,  # 词表大小可调\n",
    "        special_tokens=[\"[PAD]\", \"[UNK]\", \"<s>\", \"</s>\"],\n",
    "    )\n",
    "    tokenizer = Tokenizer(models.BPE())\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "    tokenizer.normalizer = Sequence([NFD(), Lowercase(), StripAccents()])\n",
    "    tokenizer.train_from_iterator(iter_with_progress(), trainer=trainer)\n",
    "    filename = f\"tinystories_bpe_tokenizer_{vocab_size//1000}K.json\"\n",
    "    tokenizer.save(filename)\n",
    "    hf_tokenizer = PreTrainedTokenizerFast(tokenizer_file=filename, unk_token=\"[UNK]\", pad_token=\"[PAD]\", bos_token=\"<s>\", eos_token=\"</s>\")\n",
    "    hf_tokenizer.save_pretrained(f\"tinystories_bpe_tokenizer/{vocab_size//1000}K\")\n",
    "    \n",
    "    \n",
    "    sentences = [\n",
    "        \"Once upon a time, there was a cat.\",\n",
    "        \"The cat loved to chase butterflies.\",\n",
    "        \"One day, it caught a butterfly and became friends with it.\",\n",
    "        \"huggingface transformers is a great library for NLP tasks.\",\n",
    "        \"The ephemeral zephyr whispered through the desolate moor at twilight.\",\n",
    "    ]\n",
    "\n",
    "    for sentence in sentences:\n",
    "        encoded = tokenizer.encode(sentence)\n",
    "        # print(f\"Encoded IDs for '{sentence}':\", encoded.ids)\n",
    "        print(f\"Tokens for '{sentence}':\", encoded.tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".uv-global",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
